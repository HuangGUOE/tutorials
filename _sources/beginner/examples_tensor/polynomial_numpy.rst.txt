
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/examples_tensor/polynomial_numpy.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_examples_tensor_polynomial_numpy.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_examples_tensor_polynomial_numpy.py:


Warm-up: numpy
--------------

A third order polynomial, trained to predict :math:`y=\sin(x)` from :math:`-\pi`
to :math:`pi` by minimizing squared Euclidean distance.

This implementation uses numpy to manually compute the forward pass, loss, and
backward pass.

A numpy array is a generic n-dimensional array; it does not know anything about
deep learning or gradients or computational graphs, and is just a way to perform
generic numeric computations.

.. GENERATED FROM PYTHON SOURCE LINES 16-54




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    99 2159.3709060539622
    199 1522.2897405521564
    299 1074.2944897537163
    399 759.14476716465
    499 537.3682362017037
    599 381.2474120656761
    699 271.3102532825189
    799 193.87141829321595
    899 139.30866095520653
    999 100.85391644904777
    1099 73.74495084458826
    1199 54.62974544041927
    1299 41.14812996385525
    1399 31.63778870080921
    1499 24.927580072329103
    1599 20.192181343968493
    1699 16.849824434250984
    1799 14.49032305278092
    1899 12.824401876478738
    1999 11.64801176201893
    Result: y = 0.05561969368798655 + 0.8648584401389545 x + -0.009595322676875571 x^2 + -0.09448504653446213 x^3






|

.. code-block:: default

    import numpy as np
    import math

    # Create random input and output data
    x = np.linspace(-math.pi, math.pi, 2000)
    y = np.sin(x)

    # Randomly initialize weights
    a = np.random.randn()
    b = np.random.randn()
    c = np.random.randn()
    d = np.random.randn()

    learning_rate = 1e-6
    for t in range(2000):
        # Forward pass: compute predicted y
        # y = a + b x + c x^2 + d x^3
        y_pred = a + b * x + c * x ** 2 + d * x ** 3

        # Compute and print loss
        loss = np.square(y_pred - y).sum()
        if t % 100 == 99:
            print(t, loss)

        # Backprop to compute gradients of a, b, c, d with respect to loss
        grad_y_pred = 2.0 * (y_pred - y)
        grad_a = grad_y_pred.sum()
        grad_b = (grad_y_pred * x).sum()
        grad_c = (grad_y_pred * x ** 2).sum()
        grad_d = (grad_y_pred * x ** 3).sum()

        # Update weights
        a -= learning_rate * grad_a
        b -= learning_rate * grad_b
        c -= learning_rate * grad_c
        d -= learning_rate * grad_d

    print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.719 seconds)


.. _sphx_glr_download_beginner_examples_tensor_polynomial_numpy.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: polynomial_numpy.py <polynomial_numpy.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: polynomial_numpy.ipynb <polynomial_numpy.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
